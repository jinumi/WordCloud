{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project, creates a \"word cloud\" from a text by writing a script.  This script needs to process the text, remove punctuation, ignore case and words that do not contain all alphabets, count the frequencies, and ignore uninteresting or irrelevant words.  A dictionary is the output of the `calculate_frequencies` function.  The `wordcloud` module will then generate the image from dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the input text of script, you will need to provide a file that contains text only.\n",
    "<br><br>\n",
    "Now you will need to upload your input file here so that script will be able to process it.  To do the upload, you will need an uploader widget.  Run the following cell to perform all the installs and imports for word cloud script and uploader widget.  It may take a minute for all of this to run and there will be a lot of output messages. But, be patient. Once you get the following final line of output, the code is done executing. Then you can continue on with the rest of this notebook.\n",
    "<br><br>\n",
    "**Enabling notebook extension fileupload/extension...**\n",
    "<br>\n",
    "**- Validating: <font color =green>OK</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are all the installs and imports you will need for your word cloud script and uploader widget\n",
    "\n",
    "%pip install wordcloud\n",
    "%pip install fileu  pload\n",
    "%pip install ipywidgets\n",
    "!jupyter nbextension install --py --user fileupload\n",
    "!jupyter nbextension enable --py fileupload\n",
    "\n",
    "import wordcloud\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display\n",
    "import fileupload\n",
    "import io\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was a lot. All of the installs and imports for your word cloud script and uploader widget have been completed.\n",
    "<br><br>\n",
    "To upload your text file, run the following cell that contains all the code for a custom uploader widget. Once you run this cell, a \"Browse\" button should appear below it. Click this button and navigate the window to locate your saved text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the uploader widget\n",
    "\n",
    "def _upload():\n",
    "\n",
    "    _upload_widget = fileupload.FileUploadWidget()\n",
    "\n",
    "    def _cb(change):\n",
    "        global file_contents\n",
    "        decoded = io.StringIO(change['owner'].data.decode('utf-8'))\n",
    "        filename = change['owner'].filename\n",
    "        print('Uploaded `{}` ({:.2f} kB)'.format(\n",
    "            filename, len(decoded.read()) / 2 **10))\n",
    "        file_contents = decoded.getvalue()\n",
    "\n",
    "    _upload_widget.observe(_cb, names='data')\n",
    "    display(_upload_widget)\n",
    "\n",
    "_upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The uploader widget saved the contents of your uploaded file into a string object named *file_contents* that word cloud script can process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function in the cell below iterates through the words in *file_contents*, removes punctuation, and counts the frequency of each word, ignore word case, words that do not contain all alphabets and boring words like \"and\" or \"the\".  Then used the `generate_from_frequencies` function to generate word cloud!\n",
    "<br><br>\n",
    "Storing the results of your iteration in a dictionary before passing them into wordcloud via the `generate_from_frequencies` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_frequencies(file_contents):\n",
    "    # Here is a list of punctuations and uninteresting words you can use to process your text\n",
    "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    uninteresting_words = [\"the\", \"a\", \"to\", \"if\", \"is\", \"it\", \"of\", \"and\", \"or\", \"an\", \"as\", \"i\", \"me\", \"my\", \\\n",
    "    \"we\", \"our\", \"ours\", \"you\", \"your\", \"yours\", \"he\", \"she\", \"him\", \"his\", \"her\", \"hers\", \"its\", \"they\", \"them\", \\\n",
    "    \"their\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"am\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \\\n",
    "    \"have\", \"has\", \"had\", \"do\", \"does\", \"did\", \"but\", \"at\", \"by\", \"with\", \"from\", \"here\", \"when\", \"where\", \"how\", \\\n",
    "    \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"some\", \"such\", \"no\", \"nor\", \"too\", \"very\", \"can\", \"will\", \"just\"]\n",
    "    \n",
    "    # LEARNER CODE START HERE\n",
    "    word_counter = {}\n",
    "    finalized_text = []\n",
    "    \n",
    "    for word in file_contents.split():\n",
    "        text = \"\"\n",
    "        for letter in word.lower():\n",
    "            if letter not in punctuations and letter.isalpha():\n",
    "                text += letter\n",
    "        if word not in uninteresting_words:\n",
    "            finalized_text.append(text)\n",
    "    \n",
    "    for word in finalized_text:\n",
    "        if word not in word_counter:\n",
    "            word_counter[word] = 0\n",
    "        word_counter[word] += 1\n",
    "    \n",
    "    #wordcloud\n",
    "    cloud = wordcloud.WordCloud()\n",
    "    cloud.generate_from_frequencies(word_counter)\n",
    "    return cloud.to_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display your wordcloud image\n",
    "\n",
    "myimage = calculate_frequencies(file_contents)\n",
    "plt.imshow(myimage, interpolation = 'nearest')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-crash-course",
   "graded_item_id": "Z5d28",
   "launcher_item_id": "eSjyd"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
